{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17d0de9d-d0db-439b-bdaa-5a82dde0f9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult.data already exists.\n",
      "adult.test already exists.\n",
      "adult.names already exists.\n",
      "\n",
      "All files ready in Data/ folder.\n",
      "(32561, 15)\n",
      "   age          workclass  fnlwgt   education  education-num  \\\n",
      "0   39          State-gov   77516   Bachelors             13   \n",
      "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
      "2   38            Private  215646     HS-grad              9   \n",
      "3   53            Private  234721        11th              7   \n",
      "4   28            Private  338409   Bachelors             13   \n",
      "\n",
      "        marital-status          occupation    relationship    race      sex  \\\n",
      "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
      "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
      "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
      "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
      "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week  native-country  income  \n",
      "0          2174             0              40   United-States   <=50K  \n",
      "1             0             0              13   United-States   <=50K  \n",
      "2             0             0              40   United-States   <=50K  \n",
      "3             0             0              40   United-States   <=50K  \n",
      "4             0             0              40            Cuba   <=50K  \n",
      "After Cleaning: (32561, 100)\n",
      "Training Logistic Regression...\n",
      "Training Decision Tree...\n",
      "Training KNN...\n",
      "Training Naive Bayes...\n",
      "Training Random Forest...\n",
      "Training XGBoost...\n",
      "\n",
      "Training Results:\n",
      "\n",
      "                     Accuracy       AUC  Precision    Recall  F1 Score  \\\n",
      "Logistic Regression  0.854291  0.909032   0.735361  0.616709  0.670829   \n",
      "Decision Tree        0.863197  0.910984   0.788085  0.590561  0.675173   \n",
      "KNN                  0.824044  0.858223   0.652899  0.574617  0.611262   \n",
      "Naive Bayes          0.421004  0.683264   0.290310  0.972577  0.447149   \n",
      "Random Forest        0.860587  0.916627   0.801645  0.559311  0.658903   \n",
      "XGBoost              0.878858  0.932095   0.793078  0.672194  0.727649   \n",
      "\n",
      "                          MCC  \n",
      "Logistic Regression  0.581881  \n",
      "Decision Tree        0.600632  \n",
      "KNN                  0.499843  \n",
      "Naive Bayes          0.236692  \n",
      "Random Forest        0.589463  \n",
      "XGBoost              0.654112  \n",
      "\n",
      "All models saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import urllib.request\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, precision_score,\n",
    "    recall_score, f1_score, matthews_corrcoef\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# ================================\n",
    "# Create Data Folder (if not exists)\n",
    "# ================================\n",
    "os.makedirs(\"Data\", exist_ok=True)\n",
    "\n",
    "# ================================\n",
    "# URLs from UCI Repository\n",
    "# ================================\n",
    "train_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "test_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\"\n",
    "names_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names\"\n",
    "\n",
    "# ================================\n",
    "# File Paths\n",
    "# ================================\n",
    "train_path = \"Data/adult.data\"\n",
    "test_path = \"Data/adult.test\"\n",
    "names_path = \"Data/adult.names\"\n",
    "\n",
    "# ================================\n",
    "# Download Function\n",
    "# ================================\n",
    "def download_file(url, path):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Downloading {os.path.basename(path)}...\")\n",
    "        urllib.request.urlretrieve(url, path)\n",
    "        print(\"Download complete!\")\n",
    "    else:\n",
    "        print(f\"{os.path.basename(path)} already exists.\")\n",
    "\n",
    "# ================================\n",
    "# Download Files\n",
    "# ================================\n",
    "download_file(train_url, train_path)\n",
    "download_file(test_url, test_path)\n",
    "download_file(names_url, names_path)\n",
    "\n",
    "print(\"\\nAll files ready in Data/ folder.\")\n",
    "\n",
    "# ================================\n",
    "# Load Dataset\n",
    "# ================================\n",
    "\n",
    "column_names = [\n",
    "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\",\n",
    "    \"marital-status\", \"occupation\", \"relationship\", \"race\",\n",
    "    \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\",\n",
    "    \"native-country\", \"income\"\n",
    "]\n",
    "\n",
    "# Load training data\n",
    "data = pd.read_csv(\"Data/adult.data\", header=None, names=column_names)\n",
    "\n",
    "print(data.shape)\n",
    "print(data.head())\n",
    "\n",
    "# =====================================\n",
    "#  Data Cleaning\n",
    "# =====================================\n",
    "\n",
    "# Replace '?' with NaN\n",
    "data.replace(\"?\", np.nan, inplace=True)\n",
    "\n",
    "# Drop missing rows\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Drop fnlwgt (not useful for ML)\n",
    "data.drop(\"fnlwgt\", axis=1, inplace=True)\n",
    "\n",
    "# Convert target to binary\n",
    "data[\"income\"] = data[\"income\"].apply(\n",
    "    lambda x: 1 if x.strip() == \">50K\" else 0\n",
    ")\n",
    "\n",
    "# One-hot encode categorical features\n",
    "data = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "print(\"After Cleaning:\", data.shape)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# Feature-Target Split\n",
    "# ==========================================\n",
    "\n",
    "X = data.drop(\"income\", axis=1)\n",
    "y = data[\"income\"]\n",
    "\n",
    "# Save feature column names (IMPORTANT for Streamlit)\n",
    "feature_columns = X.columns\n",
    "os.makedirs(\"Model\", exist_ok=True)\n",
    "joblib.dump(feature_columns, \"Model/feature_columns.pkl\")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# Feature Scaling\n",
    "# ==========================================\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "joblib.dump(scaler, \"Model/scaler.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# Evaluation Function (Training Set)\n",
    "# ==========================================\n",
    "\n",
    "def evaluate_model(model):\n",
    "    y_pred = model.predict(X_val_scaled)\n",
    "    y_prob = model.predict_proba(X_val_scaled)[:, 1]\n",
    "\n",
    "    return [\n",
    "        accuracy_score(y_val, y_pred),\n",
    "        roc_auc_score(y_val, y_prob),\n",
    "        precision_score(y_val, y_pred),\n",
    "        recall_score(y_val, y_pred),\n",
    "        f1_score(y_val, y_pred),\n",
    "        matthews_corrcoef(y_val, y_pred)\n",
    "    ]\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# Models\n",
    "# ==========================================\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        C=1.0\n",
    "    ),\n",
    "\n",
    "    \"Decision Tree\": DecisionTreeClassifier(\n",
    "        max_depth=10,\n",
    "        min_samples_split=20,\n",
    "        min_samples_leaf=10,\n",
    "        random_state=42\n",
    "    ),\n",
    "\n",
    "    \"KNN\": KNeighborsClassifier(\n",
    "        n_neighbors=7\n",
    "    ),\n",
    "\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=15,\n",
    "        min_samples_split=20,\n",
    "        min_samples_leaf=10,\n",
    "        random_state=42\n",
    "    ),\n",
    "\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        eval_metric=\"logloss\"\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# Train Models & Evaluate (Training Set)\n",
    "# ==========================================\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    results[name] = evaluate_model(model)\n",
    "\n",
    "    # Save trained model\n",
    "    file_name = name.lower().replace(\" \", \"_\") + \".pkl\"\n",
    "    joblib.dump(model, os.path.join(\"Model\", file_name))\n",
    "\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# Display Results\n",
    "# ==========================================\n",
    "\n",
    "results_df = pd.DataFrame(\n",
    "    results,\n",
    "    index=[\"Accuracy\", \"AUC\", \"Precision\", \"Recall\", \"F1 Score\", \"MCC\"]\n",
    ").T\n",
    "\n",
    "print(\"\\nTraining Results:\\n\")\n",
    "print(results_df)\n",
    "\n",
    "print(\"\\nAll models saved successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d540d9c-6fc3-4b18-ab29-e9d0bf2dbec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4632539-6748-432d-bf94-b408201c5ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
